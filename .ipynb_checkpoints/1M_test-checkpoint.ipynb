{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>wti</th>\n",
       "      <th>vix</th>\n",
       "      <th>diff</th>\n",
       "      <th>jpy_krw</th>\n",
       "      <th>usd_krw</th>\n",
       "      <th>ism</th>\n",
       "      <th>china_pmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-02-01</td>\n",
       "      <td>47.12</td>\n",
       "      <td>12.03</td>\n",
       "      <td>0.736</td>\n",
       "      <td>9.9161</td>\n",
       "      <td>1028.50</td>\n",
       "      <td>56.8</td>\n",
       "      <td>54.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-02-02</td>\n",
       "      <td>46.69</td>\n",
       "      <td>11.66</td>\n",
       "      <td>0.706</td>\n",
       "      <td>9.9151</td>\n",
       "      <td>1027.85</td>\n",
       "      <td>56.8</td>\n",
       "      <td>54.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-02-03</td>\n",
       "      <td>46.45</td>\n",
       "      <td>11.79</td>\n",
       "      <td>0.697</td>\n",
       "      <td>9.8172</td>\n",
       "      <td>1025.50</td>\n",
       "      <td>56.8</td>\n",
       "      <td>54.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-02-04</td>\n",
       "      <td>46.48</td>\n",
       "      <td>11.21</td>\n",
       "      <td>0.661</td>\n",
       "      <td>9.8319</td>\n",
       "      <td>1023.50</td>\n",
       "      <td>56.8</td>\n",
       "      <td>54.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-02-07</td>\n",
       "      <td>45.28</td>\n",
       "      <td>11.73</td>\n",
       "      <td>0.627</td>\n",
       "      <td>9.8169</td>\n",
       "      <td>1029.50</td>\n",
       "      <td>56.8</td>\n",
       "      <td>54.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date    wti    vix   diff  jpy_krw  usd_krw   ism  china_pmi\n",
       "0 2005-02-01  47.12  12.03  0.736   9.9161  1028.50  56.8       54.7\n",
       "1 2005-02-02  46.69  11.66  0.706   9.9151  1027.85  56.8       54.7\n",
       "2 2005-02-03  46.45  11.79  0.697   9.8172  1025.50  56.8       54.7\n",
       "3 2005-02-04  46.48  11.21  0.661   9.8319  1023.50  56.8       54.7\n",
       "4 2005-02-07  45.28  11.73  0.627   9.8169  1029.50  56.8       54.7"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 매크로 데이터 불러오기\n",
    "import pandas as pd\n",
    "\n",
    "macro = pd.read_csv(\"macro.csv\", index_col = 0)\n",
    "macro[\"date\"] = pd.to_datetime(macro[\"date\"])\n",
    "macro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>open</th>\n",
       "      <th>hign</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "      <th>change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>1132.99</td>\n",
       "      <td>1116.56</td>\n",
       "      <td>1133.87</td>\n",
       "      <td>1116.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>1136.52</td>\n",
       "      <td>1132.66</td>\n",
       "      <td>1136.63</td>\n",
       "      <td>1129.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>1137.14</td>\n",
       "      <td>1135.71</td>\n",
       "      <td>1139.19</td>\n",
       "      <td>1133.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>1141.69</td>\n",
       "      <td>1136.27</td>\n",
       "      <td>1142.46</td>\n",
       "      <td>1131.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>1144.98</td>\n",
       "      <td>1140.52</td>\n",
       "      <td>1145.39</td>\n",
       "      <td>1136.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date    close     open     hign      low  volume  change\n",
       "0 2010-01-04  1132.99  1116.56  1133.87  1116.56     0.0  0.0160\n",
       "1 2010-01-05  1136.52  1132.66  1136.63  1129.66     0.0  0.0031\n",
       "2 2010-01-06  1137.14  1135.71  1139.19  1133.95     0.0  0.0005\n",
       "3 2010-01-07  1141.69  1136.27  1142.46  1131.32     0.0  0.0040\n",
       "4 2010-01-08  1144.98  1140.52  1145.39  1136.22     0.0  0.0029"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ETF 데이터\n",
    "import FinanceDataReader as fdr\n",
    "\n",
    "kodex200 = fdr.DataReader(\"US500\", \"2010-01-01\")\n",
    "kodex200 = kodex200.reset_index()\n",
    "kodex200.columns = [\"date\", \"close\", \"open\", \"hign\", \"low\", \"volume\", \"change\"]\n",
    "kodex200.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true range\n",
    "\n",
    "high_low = []\n",
    "high_close = []\n",
    "low_close = []\n",
    "\n",
    "for i in range(0, len(kodex200)):\n",
    "    \n",
    "    # |당일 고가 - 당일 저가|\n",
    "    today_high = kodex200[\"high\"][i]\n",
    "    today_low = kodex200[\"low\"][i]\n",
    "    val_high_low = abs(today_high - today_low)\n",
    "    high_low.append(val_high_low)\n",
    "    \n",
    "    # |당일 고가 - 전일 종가|\n",
    "    if i - 1 == -1:\n",
    "        recent_close = kodex200[\"close\"][i]\n",
    "    \n",
    "    else:\n",
    "        recent_close = kodex200[\"close\"][i - 1]\n",
    "        \n",
    "    val_high_close = abs(today_high - recent_close)\n",
    "    high_close.append(val_high_close)\n",
    "    \n",
    "    # |당일 저가 - 전일 종가|\n",
    "    val_low_close = abs(today_low - recent_close)\n",
    "    low_close.append(val_low_close)\n",
    "    \n",
    "true_range = []\n",
    "\n",
    "for j in range(0, len(kodex200)):\n",
    "    tr_val = max(high_low[j], high_close[j], low_close[j])\n",
    "    true_range.append(tr_val)\n",
    "    \n",
    "kodex200[\"true_range\"] = true_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nomalized average true range\n",
    "import numpy as np\n",
    "\n",
    "natr = []\n",
    "\n",
    "for i in range(0, len(kodex200)):\n",
    "    if i + 1 < 14:\n",
    "        natr_val = np.nan\n",
    "    \n",
    "    else:\n",
    "        natr_val = kodex200[\"true_range\"][i-13:i+1].sum() / kodex200[\"close\"][i] * 100\n",
    "        \n",
    "    natr.append(natr_val)\n",
    "    \n",
    "kodex200[\"NATR\"] = natr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moving average (5, 15, 30)\n",
    "\n",
    "ma5 = []\n",
    "\n",
    "for i in range(0, len(kodex200)):\n",
    "    if i + 1 < 5:\n",
    "        ma5_val = np.nan\n",
    "        \n",
    "    else:\n",
    "        ma5_val = kodex200[\"close\"][i-4:i+1].sum() / 5\n",
    "        \n",
    "    ma5.append(ma5_val)\n",
    "    \n",
    "ma15 = []\n",
    "\n",
    "for j in range(0, len(kodex200)):\n",
    "    if j + 1 < 15:\n",
    "        ma15_val = np.nan\n",
    "        \n",
    "    else:\n",
    "        ma15_val = kodex200[\"close\"][j-14:j+1].sum() / 15\n",
    "        \n",
    "    ma15.append(ma15_val)\n",
    "    \n",
    "ma30 = []\n",
    "\n",
    "for k in range(0, len(kodex200)):\n",
    "    if k + 1 < 30:\n",
    "        ma30_val = np.nan\n",
    "        \n",
    "    else:\n",
    "        ma30_val = kodex200[\"close\"][k-29:k+1].sum() / 30\n",
    "        \n",
    "    ma30.append(ma30_val)\n",
    "    \n",
    "kodex200[\"MA5\"] = ma5\n",
    "kodex200[\"MA15\"] = ma15\n",
    "kodex200[\"MA30\"] = ma30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bollinger band (upper, middle, lower band, band width)\n",
    "\n",
    "middle_band = []\n",
    "\n",
    "for i in range(0, len(kodex200)):\n",
    "    if i + 1 < 20:\n",
    "        middle = np.nan\n",
    "        \n",
    "    else:\n",
    "        middle = kodex200[\"close\"][i-19:i+1].sum() / 20\n",
    "        \n",
    "    middle_band.append(middle)\n",
    "    \n",
    "upper_band = []\n",
    "lower_band = []\n",
    "\n",
    "for j in range(0, len(kodex200)):\n",
    "    if j + 1 < 20:\n",
    "        upper = np.nan\n",
    "        lower = np.nan\n",
    "        \n",
    "    else:\n",
    "        upper = middle_band[j] + (2 * kodex200[\"close\"][j-19:j+1].std())\n",
    "        lower = middle_band[j] - (2 * kodex200[\"close\"][j-19:j+1].std())\n",
    "        \n",
    "    upper_band.append(upper)\n",
    "    lower_band.append(lower)\n",
    "    \n",
    "kodex200[\"upper_band\"] = upper_band\n",
    "kodex200[\"middle_band\"] = middle_band\n",
    "kodex200[\"lower_band\"] = lower_band\n",
    "kodex200[\"band_width\"] = kodex200[\"upper_band\"] - kodex200[\"lower_band\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on balance volume\n",
    "\n",
    "obv = []\n",
    "\n",
    "for i in range(0, len(kodex200)):\n",
    "    if i - 1 == -1:\n",
    "        obv_val = kodex200[\"volume\"][i]\n",
    "        \n",
    "    else:\n",
    "        if kodex200[\"close\"][i] > kodex200[\"close\"][i-1]:\n",
    "            obv_val = obv_val + kodex200[\"volume\"][i]\n",
    "        \n",
    "        else:\n",
    "            obv_val = obv_val - kodex200[\"volume\"][i]\n",
    "            \n",
    "    obv.append(obv_val)\n",
    "    \n",
    "kodex200[\"OBV\"] = obv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 days momentun, 20 days momentum (영업일 기준)\n",
    "kodex200[\"close_5lag\"] = kodex200[\"close\"].shift(5)\n",
    "kodex200[\"momentum_5\"] = (kodex200[\"close\"] - kodex200[\"close_5lag\"]) / kodex200[\"close_5lag\"]\n",
    "\n",
    "kodex200[\"close_20lag\"] = kodex200[\"close\"].shift(20)\n",
    "kodex200[\"momentum_20\"] = (kodex200[\"close\"] - kodex200[\"close_20lag\"]) / kodex200[\"close_20lag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>change</th>\n",
       "      <th>true_range</th>\n",
       "      <th>NATR</th>\n",
       "      <th>MA5</th>\n",
       "      <th>...</th>\n",
       "      <th>lower_band</th>\n",
       "      <th>band_width</th>\n",
       "      <th>OBV</th>\n",
       "      <th>close_5lag</th>\n",
       "      <th>momentum_5</th>\n",
       "      <th>close_20lag</th>\n",
       "      <th>momentum_20</th>\n",
       "      <th>close_-20lag</th>\n",
       "      <th>return</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>18919</td>\n",
       "      <td>19065</td>\n",
       "      <td>18919</td>\n",
       "      <td>19048</td>\n",
       "      <td>883268</td>\n",
       "      <td>0.006074</td>\n",
       "      <td>146</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>883268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>-0.055019</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>19101</td>\n",
       "      <td>19109</td>\n",
       "      <td>18974</td>\n",
       "      <td>19029</td>\n",
       "      <td>1781284</td>\n",
       "      <td>-0.000997</td>\n",
       "      <td>135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-898016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17897.0</td>\n",
       "      <td>-0.059488</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>19056</td>\n",
       "      <td>19189</td>\n",
       "      <td>19049</td>\n",
       "      <td>19161</td>\n",
       "      <td>962659</td>\n",
       "      <td>0.006937</td>\n",
       "      <td>160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18102.0</td>\n",
       "      <td>-0.055269</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>19149</td>\n",
       "      <td>19170</td>\n",
       "      <td>18911</td>\n",
       "      <td>18924</td>\n",
       "      <td>1250996</td>\n",
       "      <td>-0.012369</td>\n",
       "      <td>259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1186353</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18081.0</td>\n",
       "      <td>-0.044547</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>18998</td>\n",
       "      <td>19006</td>\n",
       "      <td>18758</td>\n",
       "      <td>18996</td>\n",
       "      <td>1428088</td>\n",
       "      <td>0.003805</td>\n",
       "      <td>248</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19031.6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>241735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17568.0</td>\n",
       "      <td>-0.075174</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   open   high    low  close   volume    change  true_range  NATR  \\\n",
       "0 2010-01-04  18919  19065  18919  19048   883268  0.006074         146   NaN   \n",
       "1 2010-01-05  19101  19109  18974  19029  1781284 -0.000997         135   NaN   \n",
       "2 2010-01-06  19056  19189  19049  19161   962659  0.006937         160   NaN   \n",
       "3 2010-01-07  19149  19170  18911  18924  1250996 -0.012369         259   NaN   \n",
       "4 2010-01-08  18998  19006  18758  18996  1428088  0.003805         248   NaN   \n",
       "\n",
       "       MA5  ...  lower_band  band_width      OBV  close_5lag  momentum_5  \\\n",
       "0      NaN  ...         NaN         NaN   883268         NaN         NaN   \n",
       "1      NaN  ...         NaN         NaN  -898016         NaN         NaN   \n",
       "2      NaN  ...         NaN         NaN    64643         NaN         NaN   \n",
       "3      NaN  ...         NaN         NaN -1186353         NaN         NaN   \n",
       "4  19031.6  ...         NaN         NaN   241735         NaN         NaN   \n",
       "\n",
       "   close_20lag  momentum_20  close_-20lag    return  grade  \n",
       "0          NaN          NaN       18000.0 -0.055019    0.0  \n",
       "1          NaN          NaN       17897.0 -0.059488    0.0  \n",
       "2          NaN          NaN       18102.0 -0.055269    0.0  \n",
       "3          NaN          NaN       18081.0 -0.044547    0.0  \n",
       "4          NaN          NaN       17568.0 -0.075174    0.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target 생성\n",
    "def target(x):\n",
    "    if x > 0:\n",
    "        return 1\n",
    "    \n",
    "    elif x <= 0:\n",
    "        return 0\n",
    "    \n",
    "kodex200[\"close_-20lag\"] = kodex200[\"close\"].shift(-20)\n",
    "kodex200[\"return\"] = (kodex200[\"close_-20lag\"] - kodex200[\"close\"]) / kodex200[\"close\"]\n",
    "kodex200[\"grade\"] = kodex200[\"return\"].apply(target)\n",
    "\n",
    "kodex200.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>change</th>\n",
       "      <th>true_range</th>\n",
       "      <th>NATR</th>\n",
       "      <th>MA5</th>\n",
       "      <th>...</th>\n",
       "      <th>lower_band</th>\n",
       "      <th>band_width</th>\n",
       "      <th>OBV</th>\n",
       "      <th>close_5lag</th>\n",
       "      <th>momentum_5</th>\n",
       "      <th>close_20lag</th>\n",
       "      <th>momentum_20</th>\n",
       "      <th>close_-20lag</th>\n",
       "      <th>return</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>17901</td>\n",
       "      <td>17917</td>\n",
       "      <td>17611</td>\n",
       "      <td>17808</td>\n",
       "      <td>2306259</td>\n",
       "      <td>-0.004083</td>\n",
       "      <td>306</td>\n",
       "      <td>25.140386</td>\n",
       "      <td>17653.4</td>\n",
       "      <td>...</td>\n",
       "      <td>17059.138040</td>\n",
       "      <td>2391.923921</td>\n",
       "      <td>-8266806</td>\n",
       "      <td>17568.0</td>\n",
       "      <td>0.013661</td>\n",
       "      <td>19017.0</td>\n",
       "      <td>-0.063575</td>\n",
       "      <td>18437.0</td>\n",
       "      <td>0.035321</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-02-16</td>\n",
       "      <td>17791</td>\n",
       "      <td>18043</td>\n",
       "      <td>17704</td>\n",
       "      <td>17927</td>\n",
       "      <td>1197499</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>339</td>\n",
       "      <td>23.991744</td>\n",
       "      <td>17755.2</td>\n",
       "      <td>...</td>\n",
       "      <td>17062.879563</td>\n",
       "      <td>2265.940873</td>\n",
       "      <td>-7069307</td>\n",
       "      <td>17418.0</td>\n",
       "      <td>0.029223</td>\n",
       "      <td>19112.0</td>\n",
       "      <td>-0.062003</td>\n",
       "      <td>18799.0</td>\n",
       "      <td>0.048642</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-02-17</td>\n",
       "      <td>18069</td>\n",
       "      <td>18273</td>\n",
       "      <td>18069</td>\n",
       "      <td>18250</td>\n",
       "      <td>2941587</td>\n",
       "      <td>0.018018</td>\n",
       "      <td>346</td>\n",
       "      <td>24.197260</td>\n",
       "      <td>17890.2</td>\n",
       "      <td>...</td>\n",
       "      <td>17106.535717</td>\n",
       "      <td>2090.728566</td>\n",
       "      <td>-4127720</td>\n",
       "      <td>17575.0</td>\n",
       "      <td>0.038407</td>\n",
       "      <td>19129.0</td>\n",
       "      <td>-0.045951</td>\n",
       "      <td>18721.0</td>\n",
       "      <td>0.025808</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-02-18</td>\n",
       "      <td>18283</td>\n",
       "      <td>18283</td>\n",
       "      <td>18144</td>\n",
       "      <td>18183</td>\n",
       "      <td>1164540</td>\n",
       "      <td>-0.003671</td>\n",
       "      <td>139</td>\n",
       "      <td>23.378980</td>\n",
       "      <td>18009.8</td>\n",
       "      <td>...</td>\n",
       "      <td>17169.166463</td>\n",
       "      <td>1868.667073</td>\n",
       "      <td>-5292260</td>\n",
       "      <td>17585.0</td>\n",
       "      <td>0.034006</td>\n",
       "      <td>19151.0</td>\n",
       "      <td>-0.050546</td>\n",
       "      <td>18839.0</td>\n",
       "      <td>0.036078</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-02-19</td>\n",
       "      <td>18050</td>\n",
       "      <td>18197</td>\n",
       "      <td>17807</td>\n",
       "      <td>17857</td>\n",
       "      <td>2627570</td>\n",
       "      <td>-0.017929</td>\n",
       "      <td>390</td>\n",
       "      <td>22.792182</td>\n",
       "      <td>18005.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17286.020599</td>\n",
       "      <td>1489.158802</td>\n",
       "      <td>-7919830</td>\n",
       "      <td>17881.0</td>\n",
       "      <td>-0.001342</td>\n",
       "      <td>19315.0</td>\n",
       "      <td>-0.075485</td>\n",
       "      <td>18616.0</td>\n",
       "      <td>0.042504</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   open   high    low  close   volume    change  true_range  \\\n",
       "0 2010-02-12  17901  17917  17611  17808  2306259 -0.004083         306   \n",
       "1 2010-02-16  17791  18043  17704  17927  1197499  0.006682         339   \n",
       "2 2010-02-17  18069  18273  18069  18250  2941587  0.018018         346   \n",
       "3 2010-02-18  18283  18283  18144  18183  1164540 -0.003671         139   \n",
       "4 2010-02-19  18050  18197  17807  17857  2627570 -0.017929         390   \n",
       "\n",
       "        NATR      MA5  ...    lower_band   band_width      OBV  close_5lag  \\\n",
       "0  25.140386  17653.4  ...  17059.138040  2391.923921 -8266806     17568.0   \n",
       "1  23.991744  17755.2  ...  17062.879563  2265.940873 -7069307     17418.0   \n",
       "2  24.197260  17890.2  ...  17106.535717  2090.728566 -4127720     17575.0   \n",
       "3  23.378980  18009.8  ...  17169.166463  1868.667073 -5292260     17585.0   \n",
       "4  22.792182  18005.0  ...  17286.020599  1489.158802 -7919830     17881.0   \n",
       "\n",
       "   momentum_5  close_20lag  momentum_20  close_-20lag    return  grade  \n",
       "0    0.013661      19017.0    -0.063575       18437.0  0.035321    1.0  \n",
       "1    0.029223      19112.0    -0.062003       18799.0  0.048642    1.0  \n",
       "2    0.038407      19129.0    -0.045951       18721.0  0.025808    1.0  \n",
       "3    0.034006      19151.0    -0.050546       18839.0  0.036078    1.0  \n",
       "4   -0.001342      19315.0    -0.075485       18616.0  0.042504    1.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 제거\n",
    "kodex200 = kodex200.dropna(axis = 0).reset_index(drop = True)\n",
    "kodex200.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>change</th>\n",
       "      <th>true_range</th>\n",
       "      <th>NATR</th>\n",
       "      <th>MA5</th>\n",
       "      <th>...</th>\n",
       "      <th>close_-20lag</th>\n",
       "      <th>return</th>\n",
       "      <th>grade</th>\n",
       "      <th>wti</th>\n",
       "      <th>vix</th>\n",
       "      <th>diff</th>\n",
       "      <th>jpy_krw</th>\n",
       "      <th>usd_krw</th>\n",
       "      <th>ism</th>\n",
       "      <th>china_pmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>17901</td>\n",
       "      <td>17917</td>\n",
       "      <td>17611</td>\n",
       "      <td>17808</td>\n",
       "      <td>2306259</td>\n",
       "      <td>-0.004083</td>\n",
       "      <td>306</td>\n",
       "      <td>25.140386</td>\n",
       "      <td>17653.4</td>\n",
       "      <td>...</td>\n",
       "      <td>18437.0</td>\n",
       "      <td>0.035321</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.13</td>\n",
       "      <td>22.73</td>\n",
       "      <td>2.307</td>\n",
       "      <td>12.8034</td>\n",
       "      <td>1152.5</td>\n",
       "      <td>58.4</td>\n",
       "      <td>55.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-02-16</td>\n",
       "      <td>17791</td>\n",
       "      <td>18043</td>\n",
       "      <td>17704</td>\n",
       "      <td>17927</td>\n",
       "      <td>1197499</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>339</td>\n",
       "      <td>23.991744</td>\n",
       "      <td>17755.2</td>\n",
       "      <td>...</td>\n",
       "      <td>18799.0</td>\n",
       "      <td>0.048642</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.01</td>\n",
       "      <td>22.25</td>\n",
       "      <td>2.301</td>\n",
       "      <td>12.7261</td>\n",
       "      <td>1147.0</td>\n",
       "      <td>58.4</td>\n",
       "      <td>55.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-02-17</td>\n",
       "      <td>18069</td>\n",
       "      <td>18273</td>\n",
       "      <td>18069</td>\n",
       "      <td>18250</td>\n",
       "      <td>2941587</td>\n",
       "      <td>0.018018</td>\n",
       "      <td>346</td>\n",
       "      <td>24.197260</td>\n",
       "      <td>17890.2</td>\n",
       "      <td>...</td>\n",
       "      <td>18721.0</td>\n",
       "      <td>0.025808</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.33</td>\n",
       "      <td>21.72</td>\n",
       "      <td>2.309</td>\n",
       "      <td>12.5267</td>\n",
       "      <td>1144.5</td>\n",
       "      <td>58.4</td>\n",
       "      <td>55.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-02-18</td>\n",
       "      <td>18283</td>\n",
       "      <td>18283</td>\n",
       "      <td>18144</td>\n",
       "      <td>18183</td>\n",
       "      <td>1164540</td>\n",
       "      <td>-0.003671</td>\n",
       "      <td>139</td>\n",
       "      <td>23.378980</td>\n",
       "      <td>18009.8</td>\n",
       "      <td>...</td>\n",
       "      <td>18839.0</td>\n",
       "      <td>0.036078</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.06</td>\n",
       "      <td>20.63</td>\n",
       "      <td>2.298</td>\n",
       "      <td>12.5577</td>\n",
       "      <td>1145.7</td>\n",
       "      <td>58.4</td>\n",
       "      <td>55.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-02-19</td>\n",
       "      <td>18050</td>\n",
       "      <td>18197</td>\n",
       "      <td>17807</td>\n",
       "      <td>17857</td>\n",
       "      <td>2627570</td>\n",
       "      <td>-0.017929</td>\n",
       "      <td>390</td>\n",
       "      <td>22.792182</td>\n",
       "      <td>18005.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18616.0</td>\n",
       "      <td>0.042504</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.81</td>\n",
       "      <td>20.02</td>\n",
       "      <td>2.275</td>\n",
       "      <td>12.5854</td>\n",
       "      <td>1152.7</td>\n",
       "      <td>58.4</td>\n",
       "      <td>55.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   open   high    low  close   volume    change  true_range  \\\n",
       "0 2010-02-12  17901  17917  17611  17808  2306259 -0.004083         306   \n",
       "1 2010-02-16  17791  18043  17704  17927  1197499  0.006682         339   \n",
       "2 2010-02-17  18069  18273  18069  18250  2941587  0.018018         346   \n",
       "3 2010-02-18  18283  18283  18144  18183  1164540 -0.003671         139   \n",
       "4 2010-02-19  18050  18197  17807  17857  2627570 -0.017929         390   \n",
       "\n",
       "        NATR      MA5  ...  close_-20lag    return  grade    wti    vix  \\\n",
       "0  25.140386  17653.4  ...       18437.0  0.035321    1.0  74.13  22.73   \n",
       "1  23.991744  17755.2  ...       18799.0  0.048642    1.0  77.01  22.25   \n",
       "2  24.197260  17890.2  ...       18721.0  0.025808    1.0  77.33  21.72   \n",
       "3  23.378980  18009.8  ...       18839.0  0.036078    1.0  79.06  20.63   \n",
       "4  22.792182  18005.0  ...       18616.0  0.042504    1.0  79.81  20.02   \n",
       "\n",
       "    diff  jpy_krw  usd_krw   ism  china_pmi  \n",
       "0  2.307  12.8034   1152.5  58.4       55.8  \n",
       "1  2.301  12.7261   1147.0  58.4       55.8  \n",
       "2  2.309  12.5267   1144.5  58.4       55.8  \n",
       "3  2.298  12.5577   1145.7  58.4       55.8  \n",
       "4  2.275  12.5854   1152.7  58.4       55.8  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kodex200과 macro date merge\n",
    "kodex200 = pd.merge(kodex200, macro, on = \"date\", how = \"inner\").reset_index(drop = True)\n",
    "kodex200.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 머신러닝으로 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1883, 31), (741, 31))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train, test set 분리\n",
    "train = kodex200[kodex200[\"date\"] < \"2018-01-01\"].reset_index(drop = True)\n",
    "test = kodex200[kodex200[\"date\"] >= \"2018-01-01\"].reset_index(drop = True)\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요없는 칼럼 제거\n",
    "drop_col = [\"open\", \"high\", \"low\", \"close_5lag\", \"close_20lag\", \"change\", \"close_-20lag\", \"return\", \"close\", \"date\"]\n",
    "\n",
    "train = train.drop(drop_col, axis = 1)\n",
    "test = test.drop(drop_col, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    0.586298\n",
      "0.0    0.413702\n",
      "Name: grade, dtype: float64\n",
      "-------\n",
      "1.0    0.568151\n",
      "0.0    0.431849\n",
      "Name: grade, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# baseline\n",
    "print(train[\"grade\"].value_counts(normalize = True))\n",
    "print(\"-------\")\n",
    "print(test[\"grade\"].value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature, target 분리\n",
    "target = \"grade\"\n",
    "\n",
    "X_train = train.drop(target, axis = 1)\n",
    "y_train = train[target]\n",
    "\n",
    "X_test = test.drop(target, axis = 1)\n",
    "y_test = test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1000 candidates, totalling 3000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   23.6s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   54.5s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3000 out of 3000 | elapsed:  6.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[('minmaxscaler', MinMaxScaler()),\n",
       "                                             ('pca', PCA()),\n",
       "                                             ('xgbclassifier',\n",
       "                                              XGBClassifier(base_score=None,\n",
       "                                                            booster=None,\n",
       "                                                            colsample_bylevel=None,\n",
       "                                                            colsample_bynode=None,\n",
       "                                                            colsample_bytree=None,\n",
       "                                                            gamma=None,\n",
       "                                                            gpu_id=None,\n",
       "                                                            importance_type='gain',\n",
       "                                                            interaction_constraints=None,\n",
       "                                                            learning_rate=None,\n",
       "                                                            max_delta_step=None,\n",
       "                                                            max_depth=Non...\n",
       "                                        'xgbclassifier__learning_rate': [0.001,\n",
       "                                                                         0.005,\n",
       "                                                                         0.01,\n",
       "                                                                         0.05],\n",
       "                                        'xgbclassifier__max_depth': [5, 10, 15,\n",
       "                                                                     20],\n",
       "                                        'xgbclassifier__min_child_weight': [10,\n",
       "                                                                            15,\n",
       "                                                                            20,\n",
       "                                                                            25,\n",
       "                                                                            30,\n",
       "                                                                            35],\n",
       "                                        'xgbclassifier__n_estimators': [500,\n",
       "                                                                        1000],\n",
       "                                        'xgbclassifier__scale_pos_weight': [1.417198853280864,\n",
       "                                                                            1,\n",
       "                                                                            0.7056172799497866],\n",
       "                                        'xgbclassifier__subsample': [0.3, 0.4,\n",
       "                                                                     0.5]},\n",
       "                   random_state=99, scoring='f1_weighted', verbose=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 하이퍼 파라미터를 최적화한 XGBClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "pipe = make_pipeline(\n",
    "    MinMaxScaler(),\n",
    "    PCA(),\n",
    "    XGBClassifier(random_state = 99)\n",
    ")\n",
    "\n",
    "params = {\n",
    "    \"pca__n_components\" : [6, 7, 8, 9, 10],\n",
    "    \"xgbclassifier__scale_pos_weight\" : [0.586298 / 0.413702, 1, 0.413702 / 0.586298],\n",
    "    \"xgbclassifier__max_depth\" : [5, 10, 15, 20],\n",
    "    \"xgbclassifier__min_child_weight\" : [10, 15, 20, 25, 30, 35],\n",
    "    \"xgbclassifier__learning_rate\" : [0.001, 0.005, 0.01, 0.05],\n",
    "    \"xgbclassifier__subsample\" : [0.3, 0.4, 0.5],\n",
    "    \"xgbclassifier__n_estimators\" : [500, 1000],\n",
    "    \"xgbclassifier__gamma\" : [0.25, 0.5, 0.7, 1.0]\n",
    "}\n",
    "\n",
    "clf = RandomizedSearchCV(\n",
    "    pipe,\n",
    "    params,\n",
    "    n_iter = 1000,\n",
    "    cv = 3,\n",
    "    scoring = \"f1_weighted\",\n",
    "    verbose = 1,\n",
    "    n_jobs = -1,\n",
    "    random_state = 99\n",
    ")\n",
    "\n",
    "clf.fit(X_train[[\"volume\", \"NATR\", \"momentum_5\", \"momentum_20\", \"wti\", \"diff\", \"ism\", \"vix\", \"jpy_krw\", \"usd_krw\", \"china_pmi\"]], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 하이퍼파라미터:  {'xgbclassifier__subsample': 0.5, 'xgbclassifier__scale_pos_weight': 1.417198853280864, 'xgbclassifier__n_estimators': 500, 'xgbclassifier__min_child_weight': 25, 'xgbclassifier__max_depth': 15, 'xgbclassifier__learning_rate': 0.001, 'xgbclassifier__gamma': 0.5, 'pca__n_components': 8} \n",
      "\n",
      "CV accuracy score:  0.4672856817807039\n"
     ]
    }
   ],
   "source": [
    "# 최적 하이퍼 파라미터 / CV score\n",
    "print(\"최적 하이퍼파라미터: \", clf.best_params_, \"\\n\")\n",
    "print(\"CV accuracy score: \", clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"volume\", \"true_range\", \"NATR\", \"band_width\", \"OBV\", \"momentum_5\", \"momentum_20\"]\n",
    "[[\"volume\", \"NATR\", \"momentum_5\", \"momentum_20\", \"wti\", \"diff\", \"ism\", \"vix\", \"jpy_krw\", \"usd_krw\", \"china_pmi\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy score:  0.7286245353159851\n",
      "Validation score:  0.5486087831042575\n",
      "Test set accuracy score:  0.582995951417004\n"
     ]
    }
   ],
   "source": [
    "# 최적 하이퍼 파라미터를 적용한 모델의 train, test set 정확도\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pipe_opt = make_pipeline(\n",
    "    MinMaxScaler(),\n",
    "    PCA(n_components = 8),\n",
    "    XGBClassifier(n_estimators = 500, max_depth = 15, min_child_weight = 25, subsample = 0.5,\n",
    "                  learning_rate = 0.001, gamma = 0.5, scale_pos_weight = 1, random_state = 99, n_jobs = -1)\n",
    ")\n",
    "\n",
    "pipe_opt.fit(X_train[[\"volume\", \"NATR\", \"momentum_5\", \"momentum_20\", \"wti\", \"diff\", \"ism\", \"vix\", \"jpy_krw\", \"usd_krw\", \"china_pmi\"]], y_train)\n",
    "\n",
    "print(\"Train set accuracy score: \", pipe_opt.score(X_train[[\"volume\", \"NATR\", \"momentum_5\", \"momentum_20\", \"wti\", \"diff\", \"ism\", \"vix\", \"jpy_krw\", \"usd_krw\", \"china_pmi\"]], y_train))\n",
    "print(\"Validation score: \", cross_val_score(pipe_opt, X_train[[\"volume\", \"NATR\", \"momentum_5\", \"momentum_20\", \"wti\", \"diff\", \"ism\", \"vix\", \"jpy_krw\", \"usd_krw\", \"china_pmi\"]], y_train, cv = 3).mean())\n",
    "print(\"Test set accuracy score: \", pipe_opt.score(X_test[[\"volume\", \"NATR\", \"momentum_5\", \"momentum_20\", \"wti\", \"diff\", \"ism\", \"vix\", \"jpy_krw\", \"usd_krw\", \"china_pmi\"]], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "flg, ax = plt.subplots()\n",
    "pcm = plot_confusion_matrix(pipe_opt, X_test[[\"volume\", \"NATR\", \"momentum_5\", \"momentum_20\", \"wti\", \"diff\", \"ism\", \"vix\", \"jpy_krw\", \"usd_krw\", \"china_pmi\"]], y_test,\n",
    "                           cmap = plt.cm.Blues,\n",
    "                           ax = ax);\n",
    "\n",
    "plt.title(f\"Confusion matrix, n = {len(y_test)}\", fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMax scaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train[[\"volume\", \"NATR\", \"momentum_5\", \"momentum_20\", \"wti\", \"diff\", \"ism\", \"vix\", \"jpy_krw\", \"usd_krw\", \"china_pmi\"]])\n",
    "X_test_scaled = scaler.transform(X_test[[\"volume\", \"NATR\", \"momentum_5\", \"momentum_20\", \"wti\", \"diff\", \"ism\", \"vix\", \"jpy_krw\", \"usd_krw\", \"china_pmi\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape\n",
    "X_train_re = X_train_scaled.reshape(X_train_scaled.shape[0], 11, 1)\n",
    "X_test_re = X_test_scaled.reshape(X_test_scaled.shape[0], 11, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "59/59 [==============================] - 3s 30ms/step - loss: 0.6861 - accuracy: 0.5364\n",
      "Epoch 2/100\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.6782 - accuracy: 0.5879\n",
      "Epoch 3/100\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.6771 - accuracy: 0.5884\n",
      "Epoch 4/100\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.6640 - accuracy: 0.6280\n",
      "Epoch 5/100\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.6763 - accuracy: 0.5877\n",
      "Epoch 6/100\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.6705 - accuracy: 0.5952\n",
      "Epoch 7/100\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.6742 - accuracy: 0.5844\n",
      "Epoch 8/100\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.6638 - accuracy: 0.5895\n",
      "Epoch 9/100\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.6526 - accuracy: 0.6233\n",
      "Epoch 10/100\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.6648 - accuracy: 0.5877\n",
      "Epoch 11/100\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.6614 - accuracy: 0.5923\n",
      "Epoch 12/100\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.6508 - accuracy: 0.6224\n",
      "Epoch 13/100\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.6423 - accuracy: 0.6097\n",
      "Epoch 14/100\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.6475 - accuracy: 0.6262\n",
      "Epoch 15/100\n",
      "59/59 [==============================] - 2s 34ms/step - loss: 0.6469 - accuracy: 0.6293\n",
      "Epoch 16/100\n",
      "59/59 [==============================] - 2s 33ms/step - loss: 0.6431 - accuracy: 0.6387\n",
      "Epoch 17/100\n",
      "59/59 [==============================] - 2s 33ms/step - loss: 0.6427 - accuracy: 0.6194\n",
      "Epoch 18/100\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.6270 - accuracy: 0.6387\n",
      "Epoch 19/100\n",
      "59/59 [==============================] - 2s 29ms/step - loss: 0.6476 - accuracy: 0.6185\n",
      "Epoch 20/100\n",
      "59/59 [==============================] - 2s 33ms/step - loss: 0.6230 - accuracy: 0.6620\n",
      "Epoch 21/100\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.6412 - accuracy: 0.6251\n",
      "Epoch 22/100\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.6319 - accuracy: 0.6406\n",
      "Epoch 23/100\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.6369 - accuracy: 0.6270\n",
      "Epoch 24/100\n",
      "59/59 [==============================] - 2s 33ms/step - loss: 0.6309 - accuracy: 0.6518\n",
      "Epoch 25/100\n",
      "59/59 [==============================] - 2s 37ms/step - loss: 0.6190 - accuracy: 0.6553\n",
      "Epoch 26/100\n",
      "59/59 [==============================] - 2s 34ms/step - loss: 0.6225 - accuracy: 0.6483\n",
      "Epoch 27/100\n",
      "59/59 [==============================] - 2s 35ms/step - loss: 0.6215 - accuracy: 0.6434\n",
      "Epoch 28/100\n",
      "59/59 [==============================] - 2s 35ms/step - loss: 0.6291 - accuracy: 0.6455\n",
      "Epoch 29/100\n",
      "59/59 [==============================] - 2s 34ms/step - loss: 0.6223 - accuracy: 0.6533\n",
      "Epoch 30/100\n",
      "59/59 [==============================] - 2s 33ms/step - loss: 0.6097 - accuracy: 0.6649\n",
      "Epoch 31/100\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.6184 - accuracy: 0.6671\n",
      "Epoch 32/100\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.6162 - accuracy: 0.6572\n",
      "Epoch 33/100\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.6297 - accuracy: 0.6574\n",
      "Epoch 34/100\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.6087 - accuracy: 0.6758\n",
      "Epoch 35/100\n",
      "59/59 [==============================] - 2s 33ms/step - loss: 0.6302 - accuracy: 0.6522\n",
      "Epoch 36/100\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.6132 - accuracy: 0.6517\n",
      "Epoch 37/100\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.6008 - accuracy: 0.6800\n",
      "Epoch 38/100\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.5934 - accuracy: 0.6862\n",
      "Epoch 39/100\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.5894 - accuracy: 0.6770\n",
      "Epoch 40/100\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.5921 - accuracy: 0.6831\n",
      "Epoch 41/100\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.6035 - accuracy: 0.6732\n",
      "Epoch 42/100\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.5821 - accuracy: 0.6831\n",
      "Epoch 43/100\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.5805 - accuracy: 0.6765\n",
      "Epoch 44/100\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.5824 - accuracy: 0.7109\n",
      "Epoch 45/100\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.5658 - accuracy: 0.7106\n",
      "Epoch 46/100\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.5653 - accuracy: 0.7149\n",
      "Epoch 47/100\n",
      "59/59 [==============================] - 2s 29ms/step - loss: 0.5682 - accuracy: 0.7025\n",
      "Epoch 48/100\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.5488 - accuracy: 0.7080\n",
      "Epoch 49/100\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.5410 - accuracy: 0.7165\n",
      "Epoch 50/100\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.5456 - accuracy: 0.7216\n",
      "Epoch 51/100\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.5694 - accuracy: 0.7006\n",
      "Epoch 52/100\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.5350 - accuracy: 0.7152\n",
      "Epoch 53/100\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.5276 - accuracy: 0.7120\n",
      "Epoch 54/100\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.5218 - accuracy: 0.7334\n",
      "Epoch 55/100\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.5250 - accuracy: 0.7510\n",
      "Epoch 56/100\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.5187 - accuracy: 0.7334\n",
      "Epoch 57/100\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.5246 - accuracy: 0.7337\n",
      "Epoch 58/100\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.5192 - accuracy: 0.7444\n",
      "Epoch 59/100\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.5045 - accuracy: 0.7528\n",
      "Epoch 60/100\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.4983 - accuracy: 0.7624\n",
      "Epoch 61/100\n",
      "59/59 [==============================] - 2s 33ms/step - loss: 0.4974 - accuracy: 0.7560\n",
      "Epoch 62/100\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.4940 - accuracy: 0.7693\n",
      "Epoch 63/100\n",
      "59/59 [==============================] - 2s 35ms/step - loss: 0.4794 - accuracy: 0.7745\n",
      "Epoch 64/100\n",
      "59/59 [==============================] - 2s 34ms/step - loss: 0.4696 - accuracy: 0.7732\n",
      "Epoch 65/100\n",
      "59/59 [==============================] - 2s 34ms/step - loss: 0.4809 - accuracy: 0.7610\n",
      "Epoch 66/100\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.4955 - accuracy: 0.7552\n",
      "Epoch 67/100\n",
      "59/59 [==============================] - 2s 33ms/step - loss: 0.4925 - accuracy: 0.7545\n",
      "Epoch 68/100\n",
      "59/59 [==============================] - 2s 40ms/step - loss: 0.4504 - accuracy: 0.7924\n",
      "Epoch 69/100\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.5228 - accuracy: 0.7318\n",
      "Epoch 70/100\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.4466 - accuracy: 0.7875\n",
      "Epoch 71/100\n",
      "59/59 [==============================] - 2s 38ms/step - loss: 0.4391 - accuracy: 0.7978\n",
      "Epoch 72/100\n",
      "59/59 [==============================] - 2s 37ms/step - loss: 0.4414 - accuracy: 0.7874\n",
      "Epoch 73/100\n",
      "59/59 [==============================] - 2s 41ms/step - loss: 0.4608 - accuracy: 0.7658\n",
      "Epoch 74/100\n",
      "59/59 [==============================] - 2s 41ms/step - loss: 0.4434 - accuracy: 0.7923\n",
      "Epoch 75/100\n",
      "59/59 [==============================] - 2s 37ms/step - loss: 0.4302 - accuracy: 0.7996\n",
      "Epoch 76/100\n",
      "59/59 [==============================] - 2s 33ms/step - loss: 0.4229 - accuracy: 0.8129\n",
      "Epoch 77/100\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.4708 - accuracy: 0.7803\n",
      "Epoch 78/100\n",
      "59/59 [==============================] - 2s 34ms/step - loss: 0.4268 - accuracy: 0.7957\n",
      "Epoch 79/100\n",
      "59/59 [==============================] - 2s 35ms/step - loss: 0.4451 - accuracy: 0.7868\n",
      "Epoch 80/100\n",
      "59/59 [==============================] - 2s 35ms/step - loss: 0.4098 - accuracy: 0.8183\n",
      "Epoch 81/100\n",
      "59/59 [==============================] - 2s 36ms/step - loss: 0.4195 - accuracy: 0.8040\n",
      "Epoch 82/100\n",
      "59/59 [==============================] - 2s 35ms/step - loss: 0.4089 - accuracy: 0.8151\n",
      "Epoch 83/100\n",
      "59/59 [==============================] - 2s 33ms/step - loss: 0.3890 - accuracy: 0.8205\n",
      "Epoch 84/100\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.4077 - accuracy: 0.8249\n",
      "Epoch 85/100\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.3776 - accuracy: 0.8196\n",
      "Epoch 86/100\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.3797 - accuracy: 0.8285\n",
      "Epoch 87/100\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.3774 - accuracy: 0.8261\n",
      "Epoch 88/100\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.3803 - accuracy: 0.8327\n",
      "Epoch 89/100\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.3605 - accuracy: 0.8295\n",
      "Epoch 90/100\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.3913 - accuracy: 0.8046\n",
      "Epoch 91/100\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.3496 - accuracy: 0.8454\n",
      "Epoch 92/100\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.3750 - accuracy: 0.8449\n",
      "Epoch 93/100\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.3485 - accuracy: 0.8491\n",
      "Epoch 94/100\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.3736 - accuracy: 0.8259\n",
      "Epoch 95/100\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.3378 - accuracy: 0.8449\n",
      "Epoch 96/100\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.3527 - accuracy: 0.8367\n",
      "Epoch 97/100\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.3254 - accuracy: 0.8524\n",
      "Epoch 98/100\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.3521 - accuracy: 0.8416\n",
      "Epoch 99/100\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.3487 - accuracy: 0.8496\n",
      "Epoch 100/100\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.3432 - accuracy: 0.8371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbc26098be0>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.losses import Huber\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow as tf\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape = (11, 1), return_sequences = True, activation = \"relu\"))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(LSTM(256, activation = \"relu\"))\n",
    "model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "\n",
    "model.fit(X_train_re, y_train, batch_size = 32, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 1s 9ms/step - loss: 0.3642 - accuracy: 0.8343\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 4.7368 - accuracy: 0.5500\n"
     ]
    }
   ],
   "source": [
    "# 결과\n",
    "model.evaluate(X_train_re, y_train)\n",
    "\n",
    "result = model.evaluate(X_test_re, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 15, 304],\n",
       "       [ 11, 410]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred_result = []\n",
    "for pred in model.predict(X_test_re):\n",
    "    if pred > 0.5:\n",
    "        pred_result.append(1.0)\n",
    "        \n",
    "    else:\n",
    "        pred_result.append(0.0)\n",
    "        \n",
    "cf = confusion_matrix(y_test, pred_result)\n",
    "cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
